{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7373, 0.5654, 0.9389, 0.1661, 0.7422],\n",
      "        [0.5708, 0.4559, 0.1480, 0.1845, 0.8116]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7373, 0.5654, 0.9389, 0.1661, 0.7422, 0.5708, 0.4559, 0.1480, 0.1845,\n",
       "         0.8116]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show in a given shape. Doesn't change y\n",
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 8, 0, 0, 0, 7, 9, 3, 9, 3])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x,y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe233bd56d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAM1UlEQVR4nO3dYYwc9XnH8d/P18MUEzc+HDsXxzKEOAqkURx6cpISNVRWKOFFTKIkihW1bmXVtIIoSLQqolWxorxAKSThRUt1KW5MS6FIBOFWKIljkQAKQT4c19h1iSm1g7GxiVzJpoHz4Xvy4sbRYW5nj53Zne0934902t15ZnYejfzzzO5/d/+OCAGY++Y13QCA3iDsQBKEHUiCsANJEHYgiV/r5c7O8fw4Vwt6uUsglVf1fzoV456pVinstq+SdIekAUn/EBG3lq1/rhboQ15TZZcASjwZ21vWOr6Mtz0g6W8lfULSpZLW2b600+cD0F1VXrOvlvRsRDwXEack3SdpbT1tAahblbAvk/T8tMeHimWvY3uj7THbYxMar7A7AFVUCftMbwK84bO3ETEaESMRMTKo+RV2B6CKKmE/JGn5tMfvlHS4WjsAuqVK2HdIWmn7ItvnSPq8pK31tAWgbh0PvUXEa7avl/RdTQ29bY6IvbV1BqBWlcbZI+JhSQ/X1AuALuLjskAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkKk3ZbPuApJOSTkt6LSJG6mgKQP0qhb3wuxHx8xqeB0AXcRkPJFE17CHpe7afsr1xphVsb7Q9ZntsQuMVdwegU1Uv4y+PiMO2l0jaZvu/IuLR6StExKikUUla6KGouD8AHap0Zo+Iw8XtMUkPSlpdR1MA6tdx2G0vsP2WM/clXSlpT12NAahXlcv4pZIetH3mef4lIr5TS1fomYGlS0rr+76yorS+cO9gef3g6Za1e+64vXTbDV/4Yml93mM/Ka3j9ToOe0Q8J+kDNfYCoIsYegOSIOxAEoQdSIKwA0kQdiCJOr4Igz428O6LSuvPXL+0tP79K28rrX/8lRtL6+NDrc8nywbOK932f997bmn9gsdKyzgLZ3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9jnuuT94e2n98U//TWn9k5v+vLS+cvMTpfWDX/5IaR29w5kdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2O++Jn/r20vvPU4tL6UJtx9Cr7/8Gr5T9D/bb7yqchmOyoo7w4swNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzzwEDCxe2rL1v/u7Sbf/knmtL6ytUPs6+/+7LSuvXvXVzy9p3fjG/dNvJkydL63hz2p7ZbW+2fcz2nmnLhmxvs72/uF3U3TYBVDWby/hvSbrqrGU3SdoeESslbS8eA+hjbcMeEY9KOn7W4rWSthT3t0i6pua+ANSs0zfolkbEEUkqbpe0WtH2RttjtscmNN7h7gBU1fV34yNiNCJGImJkUOVvyADonk7DftT2sCQVt8fqawlAN3Qa9q2S1hf310t6qJ52AHRL23F22/dKukLSYtuHJN0i6VZJ99veIOlnkj7bzSZR7uA/Lm9Zu/zcidJtL3zoRGl93gVDpfU/veyHpfWJON2ydlou3Rb1ahv2iFjXorSm5l4AdBEflwWSIOxAEoQdSIKwA0kQdiAJvuI6B6xZ8dOOt523//nS+on7y39q+oZF2zreN3qLMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+xx3yQ83lNbfM/xyaf2R9/9rne28zm3/83ul9XN0sGv7zogzO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7HDDP0bL2zMdaT5ksSV++//3lz93Fn3s+8sQ7SusrGGevFWd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfY5YDJaj4VPqvUYvCT99eKny5+7zfZV/PqLTNncS23P7LY32z5me8+0ZZtsv2B7V/F3dXfbBFDVbC7jvyXpqhmWfz0iVhV/D9fbFoC6tQ17RDwq6XgPegHQRVXeoLve9u7iMn9Rq5Vsb7Q9ZntsQuMVdgegik7DfqekiyWtknRE0u2tVoyI0YgYiYiRQc3vcHcAquoo7BFxNCJOR8SkpG9KWl1vWwDq1lHYbQ9Pe/gpSXtarQugP7QdZ7d9r6QrJC22fUjSLZKusL1KUkg6IOnaLvaINn5050jL2tFbHinddnjgvNL6T05NltYH2ozD73jlopa1JX/3o9JtUa+2YY+IdTMsvqsLvQDoIj4uCyRB2IEkCDuQBGEHkiDsQBJ8xXUOuOCuJ1rWPjP+Z6XbvvRb5c/93m+8UFq/+IEXS+v/tnNVy9p7tKN856gVZ3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9jnuN/75x23q5dtPnlf+FdhFg78ofwJ+LbpvcGYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0epVz72vtL6Xy3++9L63fHbdbaDCjizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Iom3YbS+3/Yjtfbb32v5SsXzI9jbb+4vbRd1vF0CnZnNmf03SjRFxiaQPS7rO9qWSbpK0PSJWStpePAbQp9qGPSKORMTO4v5JSfskLZO0VtKWYrUtkq7pVpMAqntTr9ltXyjpg5KelLQ0Io5IU/8hSFrSYpuNtsdsj01ovFq3ADo267DbPl/SA5JuiIgTs90uIkYjYiQiRgY1v5MeAdRgVmG3PaipoN8TEd8uFh+1PVzUhyUd606LAOrQ9iuuti3pLkn7IuJr00pbJa2XdGtx+1BXOkSjXvyjV5tuATWZzffZL5f0+5Ketr2rWHazpkJ+v+0Nkn4m6bPdaRFAHdqGPSIeV+uf+l9TbzsAuoVP0AFJEHYgCcIOJEHYgSQIO5AEPyWNUm89/5XS+rw2czJfctvxlrXTHXWETnFmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdHJZOKplvALHFmB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSRmMz/7ckl3S3q7pElJoxFxh+1Nkv5Y0kvFqjdHxMPdahTNOL77beUrfKA3faC62fx4xWuSboyInbbfIukp29uK2tcj4rbutQegLrOZn/2IpCPF/ZO290la1u3GANTrTb1mt32hpA9KerJYdL3t3bY3217UYpuNtsdsj01ovFKzADo367DbPl/SA5JuiIgTku6UdLGkVZo6898+03YRMRoRIxExMqj5NbQMoBOzCrvtQU0F/Z6I+LYkRcTRiDgdEZOSvilpdffaBFBV27DbtqS7JO2LiK9NWz48bbVPSdpTf3sA6uKI8p8Ctv1RSY9JelpTQ2+SdLOkdZq6hA9JByRdW7yZ19JCD8WHvKZiywBaeTK260Qcn3Ee7dm8G/+4NOMk3IypA/+P8Ak6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEm2/z17rzuyXJB2ctmixpJ/3rIE3p19769e+JHrrVJ29rYiIGX//u6dhf8PO7bGIGGmsgRL92lu/9iXRW6d61RuX8UAShB1Ioumwjza8/zL92lu/9iXRW6d60lujr9kB9E7TZ3YAPULYgSQaCbvtq2w/Y/tZ2zc10UMrtg/Yftr2LttjDfey2fYx23umLRuyvc32/uJ2xjn2Guptk+0XimO3y/bVDfW23PYjtvfZ3mv7S8XyRo9dSV89OW49f81ue0DSTyV9XNIhSTskrYuI/+xpIy3YPiBpJCIa/wCG7d+R9LKkuyPiN4tlX5V0PCJuLf6jXBQRf9EnvW2S9HLT03gXsxUNT59mXNI1kv5QDR67kr4+px4ctybO7KslPRsRz0XEKUn3SVrbQB99LyIelXT8rMVrJW0p7m/R1D+WnmvRW1+IiCMRsbO4f1LSmWnGGz12JX31RBNhXybp+WmPD6m/5nsPSd+z/ZTtjU03M4OlZ6bZKm6XNNzP2dpO491LZ00z3jfHrpPpz6tqIuwzTSXVT+N/l0fEZZI+Iem64nIVszOrabx7ZYZpxvtCp9OfV9VE2A9JWj7t8TslHW6gjxlFxOHi9pikB9V/U1EfPTODbnF7rOF+fqWfpvGeaZpx9cGxa3L68ybCvkPSStsX2T5H0uclbW2gjzewvaB440S2F0i6Uv03FfVWSeuL++slPdRgL6/TL9N4t5pmXA0fu8anP4+Inv9JulpT78j/t6S/bKKHFn29S9J/FH97m+5N0r2auqyb0NQV0QZJF0jaLml/cTvUR739k6am9t6tqWANN9TbRzX10nC3pF3F39VNH7uSvnpy3Pi4LJAEn6ADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSR+CXsozIcbsp1EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now We build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((28,28))\n",
    "#-1 tells us to not worry about size\n",
    "x = x.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3062, -2.2797, -2.2119, -2.3663, -2.3080, -2.4189, -2.2832, -2.2499,\n",
      "         -2.3017, -2.3148]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#lr tells us how large of a step to get to optimum\n",
    "optimizer = optim.Adam(net.parameters(), lr=.001)\n",
    "\n",
    "\n",
    "#passes through data\n",
    "EPOCHS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epock in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.978\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[5].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[5].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
